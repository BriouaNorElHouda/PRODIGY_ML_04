{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61155,"sourceType":"datasetVersion","datasetId":39466}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.pyplot as plt\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T16:50:29.550610Z","iopub.execute_input":"2024-11-25T16:50:29.550969Z","iopub.status.idle":"2024-11-25T16:50:29.556077Z","shell.execute_reply.started":"2024-11-25T16:50:29.550939Z","shell.execute_reply":"2024-11-25T16:50:29.554908Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\n# Load data from the LeapGestRecog dataset\nDATA_PATH = '/kaggle/input/leapgestrecog/leapGestRecog'\n\n# Verify the dataset path exists\nif not os.path.exists(DATA_PATH):\n    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}\")\n\n# Load and preprocess data\nimages = []\nlabels = []\n\n# Load images from each class folder (00-09)\nfor class_idx in range(10):\n    class_dir = os.path.join(DATA_PATH, f'{class_idx:02d}')\n    print(f\"Loading class {class_idx} from {class_dir}\")\n    \n    for img_name in os.listdir(class_dir):\n        img_path = os.path.join(class_dir, img_name)\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (64, 64))\n        images.append(img)\n        labels.append(class_idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T16:50:32.482435Z","iopub.execute_input":"2024-11-25T16:50:32.482837Z","iopub.status.idle":"2024-11-25T16:50:32.575874Z","shell.execute_reply.started":"2024-11-25T16:50:32.482803Z","shell.execute_reply":"2024-11-25T16:50:32.574443Z"}},"outputs":[{"name":"stdout","text":"Loading class 0 from /kaggle/input/leapgestrecog/leapGestRecog/00\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(class_dir, img_name)\n\u001b[1;32m     19\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m---> 20\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m images\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m     22\u001b[0m labels\u001b[38;5;241m.\u001b[39mappend(class_idx)\n","\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"],"ename":"error","evalue":"OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"\n# Convert to numpy arrays\nX = np.array(images)\ny = np.array(labels)\n\n# Preprocess the data\nX = X / 255.0  # Normalize pixel values\nX = X.reshape(-1, 64, 64, 1)  # Reshape for CNN\ny = to_categorical(y, 10)  # One-hot encode labels\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"Training samples: {X_train.shape[0]}\")\nprint(f\"Testing samples: {X_test.shape[0]}\")\n\n# Create the model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    \n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    \n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Add callbacks\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)\n]\n\n# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    batch_size=32,\n    epochs=15,\n    validation_data=(X_test, y_test),\n    callbacks=callbacks\n)\n\n# Evaluate the model\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(f\"\\nTest accuracy: {test_accuracy:.4f}\")\n\n# Save the model\nmodel.save('leap_gesture_model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Plot training history\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Make predictions on test data\npredictions = model.predict(X_test)\n\n# Display some example predictions\ndef display_predictions(X_test, y_test, predictions, num_images=5):\n    plt.figure(figsize=(15, 3))\n    for i in range(num_images):\n        plt.subplot(1, num_images, i + 1)\n        plt.imshow(X_test[i].reshape(64, 64), cmap='gray')\n        true_label = np.argmax(y_test[i])\n        pred_label = np.argmax(predictions[i])\n        plt.title(f'True: {true_label}\\nPred: {pred_label}')\n        plt.axis('off')\n    plt.show()\n\ndisplay_predictions(X_test, y_test, predictions)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}